{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9905e4a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "0778b003",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "specified-scoop",
    "outputId": "ba5fe3f4-66eb-4c44-a0b4-6a4106f3b50f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "import time\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as  mpatches\n",
    "from matplotlib.patches import Arc, Rectangle, ConnectionPatch\n",
    "from matplotlib.offsetbox import  OffsetImage\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import tqdm\n",
    "\n",
    "RANDOM_SEED = 43\n",
    "\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e3eb1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "2879d646",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "AG6NHpnaF-1x"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c9c1e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "12290892",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "apart-gibson"
   },
   "outputs": [],
   "source": [
    "filename = ''\n",
    "proc_data = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceada4c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5797cab7",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "fbeb7173-9668-4828-a44f-7687bded5ad4"
   },
   "outputs": [],
   "source": [
    "N_PLAYERS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f438c",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "fa2a71e7",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "fae93022-e4aa-4cb9-8026-412100b2433b"
   },
   "outputs": [],
   "source": [
    "# Number of shots hits each player\n",
    "proc_data['poi_shots'] = proc_data.player_mask.apply(lambda x: np.sum(x==1))\n",
    "top_players = proc_data.groupby('poi').poi_shots.sum().sort_values(ascending=False).head(N_PLAYERS).index\n",
    "\n",
    "## Filter out rallies of top N players that have hit the most shots\n",
    "proc_data = proc_data[proc_data.poi.isin(top_players)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a50370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_act_pairs(row):\n",
    "    poi = row['poi']\n",
    "    \n",
    "    sa_pairs = []\n",
    "    \n",
    "    for i in range(len(row['fv'])-1):\n",
    "        shot = row['fv'][i]\n",
    "        next_shot = row['fv'][i+1]\n",
    "        if shot[0] == poi:\n",
    "            pass\n",
    "        if shot[0] != poi and next_shot[0] == poi:\n",
    "            sa_pair = (shot, next_shot)\n",
    "            sa_pairs.append(sa_pair)\n",
    "    return sa_pairs\n",
    "\n",
    "state_action_pairs = np.concatenate((proc_data.apply(get_state_act_pairs, axis=1).values), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0802db1e",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "80c8caec",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "burning-pastor"
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(state_action_pairs.reshape(-1, state_action_pairs.shape[-1])[..., 9:-1])\n",
    "\n",
    "state_action_pairs[:, 0, 9:-1] = scaler.transform(state_action_pairs[:, 0, 9:-1])\n",
    "state_action_pairs[:, 1, 9:-1] = scaler.transform(state_action_pairs[:, 1, 9:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8ecc1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "4a2e587d",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "binary-default"
   },
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self, input_shape, output_shape, hidden_size=256, embedding_size=8):\n",
    "        super().__init__()\n",
    "        hidden_size = hidden_size\n",
    "        embedding_size = embedding_size\n",
    "        \n",
    "        self.l1 = torch.nn.Linear(input_shape+2*embedding_size, hidden_size)\n",
    "        self.l2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        #self.l3 = torch.nn.Linear(hidden_size, output_shape)\n",
    "        self.mean_head = torch.nn.Linear(hidden_size, output_shape)\n",
    "        self.log_std_head = torch.nn.Linear(hidden_size, output_shape)\n",
    "        \n",
    "        self.player_embeddings = torch.nn.Embedding(250, embedding_size)\n",
    "        \n",
    "    def forward(self, state, z, poi_idxs, opp_idxs):\n",
    "        poi_embeddings = self.player_embeddings(poi_idxs.long())\n",
    "        opp_embeddings = self.player_embeddings(opp_idxs.long())\n",
    "\n",
    "        x = torch.cat((state, z, poi_embeddings, opp_embeddings), dim=-1).float()\n",
    "        \n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        mean = self.mean_head(x)\n",
    "        log_std = self.log_std_head(x).clamp(min=-20, max=2)\n",
    "        \n",
    "        return mean, log_std\n",
    "    \n",
    "    def sample(self, state, z, poi_idxs, opp_idxs):\n",
    "        mean, log_std = self.forward(state, z, poi_idxs, opp_idxs)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = torch.distributions.normal.Normal(mean, std)\n",
    "        x_t = normal.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        log_prob -= torch.log((1 - y_t.pow(2)) + 1e-5)\n",
    "        log_prob = log_prob.sum(-1, keepdim=True)\n",
    "        \n",
    "        return action, log_prob, torch.tanh(mean)\n",
    "    \n",
    "    def get_dist(self, state, z, poi_idxs, opp_idxs):\n",
    "        mean, log_std = self.forward(state, z, poi_idxs, opp_idxs)\n",
    "        std = log_std.exp()\n",
    "        \n",
    "        normal = torch.distributions.normal.Normal(mean, std)\n",
    "        \n",
    "        return normal\n",
    "    \n",
    "    \n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size=256, embedding_size=8):\n",
    "        super().__init__()\n",
    "        hidden_size = hidden_size\n",
    "        embedding_size = embedding_size\n",
    "        \n",
    "        self.l1 = torch.nn.Linear(input_shape+2*embedding_size, hidden_size)\n",
    "        self.l2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.l3 = torch.nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        self.player_embeddings = torch.nn.Embedding(250, embedding_size)\n",
    "        \n",
    "    def forward(self, state, action, poi_idxs, opp_idxs):\n",
    "        poi_embeddings = self.player_embeddings(poi_idxs.long())\n",
    "        opp_embeddings = self.player_embeddings(opp_idxs.long())\n",
    "        \n",
    "        x = torch.cat((state, action, poi_embeddings, opp_embeddings), dim=-1).float()\n",
    "        \n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = self.l3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b393c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "992f9386",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "possible-breeding",
    "outputId": "194b09fd-0fd1-4745-aa55-2e06ce5915d6"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "hidden_size = 256\n",
    "embedding_size = 8\n",
    "latent_size = 8\n",
    "\n",
    "generator = Generator(state_action_pairs.shape[-1]+latent_size-1, len(cols_of_interest), hidden_size=hidden_size, embedding_size=embedding_size).to(device)\n",
    "discriminator = Discriminator(state_action_pairs.shape[-1]-1+len(cols_of_interest), hidden_size=hidden_size, embedding_size=embedding_size).to(device)\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "print('Generator params: ', get_n_params(generator))\n",
    "print('Discriminator params: ', get_n_params(discriminator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053dcd86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "gradient": {
     "editing": false,
     "id": "c3ad1cc0",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "1d8265f8-580a-460f-9648-41b108d3bae5",
    "outputId": "b1b0b9cd-4e8d-4655-db9e-bceb91796666"
   },
   "outputs": [],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(state_action_pairs, batch_size=256, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dc8455",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c1db4739",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "id": "harmful-night"
   },
   "outputs": [],
   "source": [
    "optimizerG = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
    "optimizerD = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
    "\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "\n",
    "tau = 0.4\n",
    "alpha = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae85c1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "f85d7197",
     "kernelId": "fff5c8ee-4ddb-4dc2-b149-6cd38266a799"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pbar = tqdm.tqdm(range(1000))\n",
    "\n",
    "I = 100\n",
    "\n",
    "for epoch in pbar:\n",
    "    for iteration, sample in enumerate(trainLoader):\n",
    "        sample = torch.tensor(sample).to(device).float()\n",
    "        state = sample[:, 0]\n",
    "        action = sample[:, 1]\n",
    "        \n",
    "        opp_idxs = state[..., 0]\n",
    "        state = state[..., 1:]\n",
    "        poi_idxs = action[..., 0]\n",
    "        action = action[..., cols_of_interest]\n",
    "        \n",
    "        # Train discriminator\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(state.size(0), latent_size).to(device)\n",
    "            fake_action, _, _ = generator.sample(state, z, poi_idxs, opp_idxs)\n",
    "        \n",
    "        real_weight = discriminator(state, action, poi_idxs, opp_idxs)\n",
    "        fake_weight = discriminator(state, fake_action, poi_idxs, opp_idxs)\n",
    "        \n",
    "        target_dist = torch.distributions.normal.Normal(action, torch.tensor([0.3]).to(device))\n",
    "        \n",
    "        #discriminator_loss = ((real_weight-1)**2).mean() + (fake_weight**2).mean()\n",
    "        target_score = 1+alpha*(tau*target_dist.log_prob(fake_action).sum(dim=-1, keepdim=True)).clip(max=0, min=-1)\n",
    "        discriminator_loss = ((real_weight-1)**2).mean() + ((fake_weight - target_score)**2).mean()\n",
    "        \n",
    "        optimizerD.zero_grad()\n",
    "        discriminator_loss.backward()\n",
    "        optimizerD.step()\n",
    "        \n",
    "        discriminator_losses.append(discriminator_loss.item())\n",
    "        \n",
    "        # Train generator        \n",
    "        z = torch.randn(state.size(0), latent_size).to(device)\n",
    "        gen_action, log_prob, _ = generator.sample(state, z, poi_idxs, opp_idxs)\n",
    "        #gen_acts = sample[:, 1].clone()\n",
    "        #gen_acts[..., cols_of_interest] = gen_action\n",
    "        #gen_acts = gen_acts[..., 1:]\n",
    "        gen_weight = discriminator(state, gen_action, poi_idxs, opp_idxs)\n",
    "        \n",
    "        #generator_loss = ((gen_weight-1)**2).mean() + tau * log_prob.mean()\n",
    "        generator_loss = (-gen_weight).mean() + tau * log_prob.mean()\n",
    "        \n",
    "        optimizerG.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        generator_losses.append(generator_loss.item())\n",
    "        \n",
    "        mse_loss = ((sample[:, 1][..., cols_of_interest] - gen_action)**2).mean() # Logging\n",
    "        \n",
    "        if iteration % I == 0:\n",
    "            pbar.set_postfix({'GenL': np.mean(generator_losses[-I:]), \n",
    "                              'DisL': np.mean(discriminator_losses[-I:]),\n",
    "                              'MSE': mse_loss.item(),\n",
    "                              'RW': real_weight.mean().item(),\n",
    "                              'GW': fake_weight.mean().item(),})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a3477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab98d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_Attempt2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
